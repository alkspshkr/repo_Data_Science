{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для \"Викишоп\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание проекта\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. \n",
    "\n",
    "Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Условие заказчика**: метрика качества `F1` не меньше **0,75**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Содержание\n",
    "\n",
    "1. Знакомство с данными\n",
    "2. Подготовка данных\n",
    "3. Обучение разных моделей\n",
    "4. Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Знакомство с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала посмотрим на предоставленные данные заказчиком: набор данных с разметкой о токсичности правок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in d:\\anaconda\\lib\\site-packages (1.0.6)\n",
      "Requirement already satisfied: numpy>=1.16.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.21.5)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from catboost) (1.7.3)\n",
      "Requirement already satisfied: pandas>=0.24.0 in d:\\anaconda\\lib\\site-packages (from catboost) (1.4.2)\n",
      "Requirement already satisfied: graphviz in d:\\anaconda\\lib\\site-packages (from catboost) (0.20)\n",
      "Requirement already satisfied: plotly in d:\\anaconda\\lib\\site-packages (from catboost) (5.6.0)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda\\lib\\site-packages (from catboost) (3.5.1)\n",
      "Requirement already satisfied: six in d:\\anaconda\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda\\lib\\site-packages (from pandas>=0.24.0->catboost) (2021.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (3.0.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (9.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda\\lib\\site-packages (from matplotlib->catboost) (1.3.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in d:\\anaconda\\lib\\site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    !pip install catboost\n",
    "except:\n",
    "    %pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# имопрт библиотек для работы с данными\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Alexander\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# импорт библиотек для работы с текстом\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('punkt');\n",
    "nltk.download('wordnet');\n",
    "nltk.download('omw-1.4');\n",
    "nltk.download('stopwords');\n",
    "nltk.download('averaged_perceptron_tagger');\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "display(data.head())\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Имеем практически 160 тысяч комментариев, объем датасета составляет 2.5 МБ. Видим, что таблица имеет два столбца:\n",
    "\n",
    "* `text` - текст комментария;\n",
    "* `toxic` - разметка токсичности комментария\n",
    "    * **0** - комментарий нетоксичен;\n",
    "    * **1** - комментарий токсичен.\n",
    "\n",
    "Для решения задачи будем прогнозировать целевой признак `toxic`. Для этого посмотрим на соотношение классов в выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обработка пропусков**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на количество пропусков в наших данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0.0\n",
       "toxic    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе общей информации о датасете и проверки на наличие пропусков, можем скзазать, что пропусков нет.\n",
    "\n",
    "Теперь посмотрим на наличие дубликатов:\n",
    "\n",
    "**Обработка дубликатов**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов в данных нет. Теперь посмотрим на соотношение классов в выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898321\n",
       "1    0.101679\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что классы в предоставленных данных несбалансированы. При проектировании моделей прогнозирования необходимо учесть эту проблему."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В процессе знакомства с данными обнаружили следующие проблемы:\n",
    "\n",
    "1. В текстах комментариев имеются лишние символы. Необходимо провести фильтрацию лишних значений;\n",
    "2. Необходимо для обучения сформировать набор комментариев в лемматизированном виде;\n",
    "3. Учесть сильный дисбаланс классов при обучении модели.\n",
    "\n",
    "На данный момент, данные не готовы для предобработки. Необходимо провести подготовку данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала важно учесть следующие проблемы:\n",
    "\n",
    "1. Какие модели будем использовать для обучения?\n",
    "2. Как будем проводить фильтрацию?\n",
    "3. Как будем представлять наши данные в векотрном виде? \n",
    "\n",
    "Для решения задачи заказчика предлагается использовать следующие модели:\n",
    "\n",
    "* Подбор моделей:\n",
    "    1. `LinearRegression()`;\n",
    "    2. `RandomForestClassifier()`;\n",
    "    3. `CatBoostClassifier()`;\n",
    "    4. `LGBMCLassifier()`;\n",
    "\n",
    "* Фильтрацию будем проводить следующим образом:\n",
    "    1. Фильтрация лишних значений;\n",
    "    2. Реализация лемматизации для отфильтрованного от лишних символов в тексте. \n",
    "\n",
    "* Отфильтрованные данные будем представлять в следующем виде:\n",
    "    1. Мешок слов;\n",
    "    2. `TF-IDF`; \n",
    "\n",
    "Приступим к выполнению задания.\n",
    "\n",
    "Для начала реализуем очистку от лишних символов. Данная процедура будет реализовываться при инициализации объекта класса. Так как для корректной работы необходимо избавляться от некорректных симоволов. Поэтому приняли решение очищать от символов всегда."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Скрипт-класс для прогнозирования класса токсичности текста\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    nlp_prepoc - отцовский класс инициализизатор. \n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    С его помощью выполняется вся необходимая предобработка текста:\n",
    "        . Очисктка от лишних символов\n",
    "        . Лемматазция\n",
    "        . Формирование корпуса текста\n",
    "        . Разбиение на выборки: тестовая и обучающая\n",
    "        . После инициализации удаляются лишние для обучения данные\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    models - класс для обучения моделей\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    Наследует все атрибуты от отцовского класса\n",
    "    В данном классе реализованы следующие методы:\n",
    "    . take_params - возвращает набор параметров для указанной модели обучения\n",
    "        ARGS: model_type - имя модели\n",
    "\n",
    "    . pipeline - возвращает сформированный пайплайн\n",
    "        ARGS: model - указанная модель\n",
    "              vector - указанный векторизатор\n",
    "\n",
    "    . take_res - возвращает результат обучения пайплайна (точнее лучшую модель для обучения). \n",
    "                 используется грубый перебор и трехкратная кросс-валидация\n",
    "        ARGS: model - указанная модель\n",
    "              vector - указанный векторизатор\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "    КАК ИНИЦИАЛИЗИРОВАТЬ КЛАСС?\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@   \n",
    "    . передать датафрейм\n",
    "    . указать фичи (текст)\n",
    "    . указать ЦП (таргет)\n",
    "    . нужна ли лемматизация? (True/False) \n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "Для обучения:\n",
    "    . определить инициализатор вне класса;\n",
    "    . определить модель вне класса.\n",
    "ПЕРЕДАВАТЬ ТАК: obj_name.take_res(model, vector)\n",
    "@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n",
    "'''\n",
    "\n",
    "\n",
    "class nlp_preproc:\n",
    "    def __init__(self, data: pd.DataFrame, \n",
    "    target: str, \n",
    "    text_features: str,\n",
    "    lemma = None):\n",
    "\n",
    "        self.data = data.copy()\n",
    "        self.data['text filter'] = self.data[text_features].apply(self.clear_value)\n",
    "        \n",
    "        if lemma:\n",
    "            self.data['lemm_text'] = self.data['text filter'].apply(self.lemmatize)\n",
    "            print('Your features are lemmatized!')\n",
    "            self.feature = self.data['lemm_text']\n",
    "        else:\n",
    "            print('Your features are not lemmatized! Initialize param \"lemm\" for lemmatize')\n",
    "            self.feature = self.data['text filter']\n",
    "\n",
    "        self.target = self.data[target]\n",
    "\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test =  (\n",
    "            train_test_split(self.feature, self.target, test_size=.2, random_state=54321, stratify=self.target))\n",
    "        \n",
    "## ПРАВКИ ПО ЗАМЕЧНИЮ: ДОБАВЛЕН УЧЕТ POS-тега\n",
    "\n",
    "    def get_wordnetpos(self, text):\n",
    "        tag = nltk.pos_tag([text])[0][1][0]\n",
    "        tag_dict = {'J': wordnet.ADJ,\n",
    "                   'N': wordnet.NOUN,\n",
    "                   'V': wordnet.VERB,\n",
    "                   'R': wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "    \n",
    "    def lemmatize(self, text):\n",
    "        text = text.lower()\n",
    "        m = WordNetLemmatizer()\n",
    "        word_txt = word_tokenize(text)\n",
    "        return ' '.join([m.lemmatize(txt, self.get_wordnetpos(txt)) for txt in word_txt])\n",
    "         \n",
    "    def clear_value(self, text):\n",
    "        return ' '.join(re.sub(r'[^a-zA-Z]', ' ', text).split())\n",
    "\n",
    "class models(nlp_preproc):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        nlp_preproc.__init__(self, *args, **kwargs)\n",
    "        del self.feature\n",
    "        del self.data\n",
    "        del self.target\n",
    "        self.test_list = []\n",
    "        self.train_list = []\n",
    "        self.vector_list = []\n",
    "        self.model_index = []\n",
    "\n",
    "    @staticmethod\n",
    "    def take_params(model_type: str):\n",
    "        if 'LogisticRegression' in model_type:\n",
    "            params = {\n",
    "                'mod__random_state' : [54321],\n",
    "                'mod__class_weight' : ['balanced'],\n",
    "                'mod__C': [15],\n",
    "                'mod__solver' : ['liblinear'],\n",
    "                'mod__max_iter': [1000]\n",
    "            }\n",
    "        elif 'RandomForest' in model_type:\n",
    "            params = {\n",
    "                'mod__random_state' : [54321],\n",
    "                'mod__class_weight' : ['balanced'],\n",
    "                'mod__n_estimators' : [51,56,5],\n",
    "                'mod__criterion' : ['gini', 'entropy']\n",
    "            }\n",
    "        elif 'CatBoost' in model_type:\n",
    "            params = {\n",
    "                'mod__iterations' : [100],\n",
    "                'mod__eval_metric' : ['TotalF1'],\n",
    "                'mod__learning_rate' : [1],\n",
    "                'mod__random_seed' : [54321],\n",
    "                'mod__depth' : [120],\n",
    "                'mod__thread_count' : [-1],\n",
    "                'mod__bootstrap_type' : ['MVS'],\n",
    "                'mod__grow_policy' : ['Lossguide']\n",
    "            } \n",
    "        elif 'LGBM' in model_type:\n",
    "            params = {\n",
    "                'mod__n_estimators': [200],\n",
    "                'mod__num_leaves': [1000,1300,250],\n",
    "                'mod__max_depth' : [50],\n",
    "                'mod__learning_rate' : [0.2],\n",
    "                'mod__class_weight': ['balanced'],\n",
    "                'mod__random_state':[54321],\n",
    "                'mod__n_jobs' : [3]\n",
    "            }           \n",
    "        return params\n",
    "\n",
    "    @staticmethod\n",
    "    def pipeline(self, model, vector):\n",
    "        pipe = Pipeline([('vec', vector),\n",
    "        ('mod', model)])\n",
    "        return pipe\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_search(self, model, vector):\n",
    "        self.grid = GridSearchCV(self.pipeline(self, model, vector), \n",
    "        self.take_params(model.__class__.__name__),\n",
    "         cv = 3, \n",
    "         scoring='f1',\n",
    "         n_jobs=3,\n",
    "         verbose = 15)\n",
    "\n",
    "        self.grid.fit(self.X_train, self.y_train)\n",
    "        print(f'The best F1-score of {model.__class__.__name__} : {self.grid.best_score_:.3f}')\n",
    "\n",
    "        self.model_index.append(model.__class__.__name__)\n",
    "        self.train_list.append(self.grid.best_score_)\n",
    "        self.vector_list.append(vector.__class__.__name__)\n",
    "        return self.grid.best_estimator_;\n",
    "\n",
    "    def take_res(self, model, vector):\n",
    "        model = self.grid_search(self, model, vector)\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        prediction = model.predict(self.X_test)\n",
    "        print(f'The final F1-score for test with {model.__class__.__name__}: {f1_score(self.y_test, prediction):.3f}')\n",
    "        self.test_list.append(f1_score(self.y_test, prediction))\n",
    "        del model\n",
    "\n",
    "    def take_report(self):\n",
    "        df = pd.DataFrame({\n",
    "            'vectorizer': self.vector_list,\n",
    "            'train results': self.train_list,\n",
    "            'test results': self.test_list}, index = self.model_index)\n",
    "        return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your features are not lemmatized! Initialize param \"lemm\" for lemmatize\n"
     ]
    }
   ],
   "source": [
    "res = nlp_preproc(data, \n",
    "target='toxic', \n",
    "text_features='text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на полученные результат обработки текста:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation Why the edits made under my userna...\n",
       "1    D aww He matches this background colour I m se...\n",
       "2    Hey man I m really not trying to edit war It s...\n",
       "3    More I can t make any real suggestions on impr...\n",
       "4    You sir are my hero Any chance you remember wh...\n",
       "Name: text filter, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.feature[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что от лишних символов мы избавились. Теперь проведем лемматизациию нашего отфильтрованного столбца."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explanation why the edits make under my userna...\n",
       "1    d aww he match this background colour i m seem...\n",
       "2    hey man i m really not try to edit war it s ju...\n",
       "3    more i can t make any real suggestion on impro...\n",
       "4    you sir be my hero any chance you remember wha...\n",
       "Name: text filter, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.data['text filter'].apply(res.lemmatize).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что все комментарии приведены к лемматизированному виду, теперь можно приступить к обучению моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "del res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В процессе предобработки данных, устранили следующие проблемы:\n",
    "\n",
    "1. Удалили ненужные символы;\n",
    "2. Провели лемматизацию данных.\n",
    "\n",
    "После предобработки данных приступим к обучению моделей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед обучением моделей необходимо выбрать в каком векторном представлении будут наши данные?\n",
    "\n",
    "Для этого попробуем представить в трех вариантах:\n",
    "\n",
    "1. Мешок слов;\n",
    "2. `TF-IDF`;\n",
    "\n",
    "Данную процедуру будем выполнять внутри класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stoplist = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем векторизаторы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# используем float для работы с LGBM\n",
    "count_vector = CountVectorizer(stop_words=stoplist, dtype=np.float32)\n",
    "tf_vector = TfidfVectorizer(stop_words=stoplist, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your features are lemmatized!\n"
     ]
    }
   ],
   "source": [
    "test = models(data, \n",
    "target='toxic', \n",
    "text_features='text',\n",
    "lemma = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Мешок слов**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "The best F1-score of LogisticRegression : 0.748\n",
      "The final F1-score for test with Pipeline: 0.752\n"
     ]
    }
   ],
   "source": [
    "test.take_res(LogisticRegression(), count_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "The best F1-score of RandomForestClassifier : 0.633\n",
      "The final F1-score for test with Pipeline: 0.646\n"
     ]
    }
   ],
   "source": [
    "test.take_res(RandomForestClassifier(), count_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "0:\tlearn: 0.9060093\ttotal: 2.88s\tremaining: 4m 45s\n",
      "1:\tlearn: 0.9365670\ttotal: 8.55s\tremaining: 6m 59s\n",
      "2:\tlearn: 0.9429951\ttotal: 13.8s\tremaining: 7m 26s\n",
      "3:\tlearn: 0.9461877\ttotal: 19.5s\tremaining: 7m 47s\n",
      "4:\tlearn: 0.9486988\ttotal: 25s\tremaining: 7m 55s\n",
      "5:\tlearn: 0.9499304\ttotal: 31s\tremaining: 8m 5s\n",
      "6:\tlearn: 0.9510358\ttotal: 36.8s\tremaining: 8m 9s\n",
      "7:\tlearn: 0.9518343\ttotal: 42.7s\tremaining: 8m 10s\n",
      "8:\tlearn: 0.9526022\ttotal: 48.5s\tremaining: 8m 10s\n",
      "9:\tlearn: 0.9531764\ttotal: 54.6s\tremaining: 8m 11s\n",
      "10:\tlearn: 0.9539571\ttotal: 1m\tremaining: 8m 10s\n",
      "11:\tlearn: 0.9544402\ttotal: 1m 6s\tremaining: 8m 8s\n",
      "12:\tlearn: 0.9550403\ttotal: 1m 12s\tremaining: 8m 5s\n",
      "13:\tlearn: 0.9555056\ttotal: 1m 18s\tremaining: 8m\n",
      "14:\tlearn: 0.9562447\ttotal: 1m 24s\tremaining: 7m 58s\n",
      "15:\tlearn: 0.9565560\ttotal: 1m 30s\tremaining: 7m 54s\n",
      "16:\tlearn: 0.9568980\ttotal: 1m 36s\tremaining: 7m 50s\n",
      "17:\tlearn: 0.9574475\ttotal: 1m 42s\tremaining: 7m 46s\n",
      "18:\tlearn: 0.9575745\ttotal: 1m 48s\tremaining: 7m 42s\n",
      "19:\tlearn: 0.9577659\ttotal: 1m 54s\tremaining: 7m 38s\n",
      "20:\tlearn: 0.9578352\ttotal: 2m\tremaining: 7m 33s\n",
      "21:\tlearn: 0.9578608\ttotal: 2m 6s\tremaining: 7m 29s\n",
      "22:\tlearn: 0.9580945\ttotal: 2m 12s\tremaining: 7m 24s\n",
      "23:\tlearn: 0.9581382\ttotal: 2m 18s\tremaining: 7m 19s\n",
      "24:\tlearn: 0.9581564\ttotal: 2m 24s\tremaining: 7m 14s\n",
      "25:\tlearn: 0.9587472\ttotal: 2m 30s\tremaining: 7m 8s\n",
      "26:\tlearn: 0.9587835\ttotal: 2m 36s\tremaining: 7m 3s\n",
      "27:\tlearn: 0.9587217\ttotal: 2m 42s\tremaining: 6m 58s\n",
      "28:\tlearn: 0.9587631\ttotal: 2m 48s\tremaining: 6m 53s\n",
      "29:\tlearn: 0.9588486\ttotal: 2m 55s\tremaining: 6m 48s\n",
      "30:\tlearn: 0.9588899\ttotal: 3m 1s\tremaining: 6m 43s\n",
      "31:\tlearn: 0.9589129\ttotal: 3m 7s\tremaining: 6m 37s\n",
      "32:\tlearn: 0.9589219\ttotal: 3m 13s\tremaining: 6m 32s\n",
      "33:\tlearn: 0.9589038\ttotal: 3m 19s\tremaining: 6m 27s\n",
      "34:\tlearn: 0.9588784\ttotal: 3m 25s\tremaining: 6m 21s\n",
      "35:\tlearn: 0.9589916\ttotal: 3m 31s\tremaining: 6m 16s\n",
      "36:\tlearn: 0.9590318\ttotal: 3m 37s\tremaining: 6m 11s\n",
      "37:\tlearn: 0.9590375\ttotal: 3m 43s\tremaining: 6m 5s\n",
      "38:\tlearn: 0.9590489\ttotal: 3m 50s\tremaining: 5m 59s\n",
      "39:\tlearn: 0.9590489\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "40:\tlearn: 0.9590744\ttotal: 4m 2s\tremaining: 5m 48s\n",
      "41:\tlearn: 0.9590586\ttotal: 4m 8s\tremaining: 5m 42s\n",
      "42:\tlearn: 0.9590660\ttotal: 4m 14s\tremaining: 5m 37s\n",
      "43:\tlearn: 0.9590824\ttotal: 4m 20s\tremaining: 5m 31s\n",
      "44:\tlearn: 0.9591045\ttotal: 4m 26s\tremaining: 5m 25s\n",
      "45:\tlearn: 0.9590955\ttotal: 4m 32s\tremaining: 5m 20s\n",
      "46:\tlearn: 0.9590921\ttotal: 4m 38s\tremaining: 5m 14s\n",
      "47:\tlearn: 0.9590921\ttotal: 4m 44s\tremaining: 5m 8s\n",
      "48:\tlearn: 0.9590683\ttotal: 4m 50s\tremaining: 5m 2s\n",
      "49:\tlearn: 0.9590938\ttotal: 4m 57s\tremaining: 4m 57s\n",
      "50:\tlearn: 0.9594409\ttotal: 5m 2s\tremaining: 4m 51s\n",
      "51:\tlearn: 0.9594285\ttotal: 5m 9s\tremaining: 4m 45s\n",
      "52:\tlearn: 0.9594245\ttotal: 5m 15s\tremaining: 4m 39s\n",
      "53:\tlearn: 0.9593809\ttotal: 5m 21s\tremaining: 4m 33s\n",
      "54:\tlearn: 0.9593842\ttotal: 5m 27s\tremaining: 4m 27s\n",
      "55:\tlearn: 0.9595073\ttotal: 5m 33s\tremaining: 4m 21s\n",
      "56:\tlearn: 0.9596936\ttotal: 5m 39s\tremaining: 4m 16s\n",
      "57:\tlearn: 0.9598693\ttotal: 5m 45s\tremaining: 4m 10s\n",
      "58:\tlearn: 0.9600753\ttotal: 5m 51s\tremaining: 4m 4s\n",
      "59:\tlearn: 0.9602106\ttotal: 5m 57s\tremaining: 3m 58s\n",
      "60:\tlearn: 0.9604287\ttotal: 6m 3s\tremaining: 3m 52s\n",
      "61:\tlearn: 0.9606394\ttotal: 6m 9s\tremaining: 3m 46s\n",
      "62:\tlearn: 0.9608564\ttotal: 6m 15s\tremaining: 3m 40s\n",
      "63:\tlearn: 0.9610051\ttotal: 6m 21s\tremaining: 3m 34s\n",
      "64:\tlearn: 0.9612250\ttotal: 6m 28s\tremaining: 3m 28s\n",
      "65:\tlearn: 0.9615729\ttotal: 6m 34s\tremaining: 3m 23s\n",
      "66:\tlearn: 0.9619360\ttotal: 6m 39s\tremaining: 3m 17s\n",
      "67:\tlearn: 0.9621684\ttotal: 6m 46s\tremaining: 3m 11s\n",
      "68:\tlearn: 0.9623520\ttotal: 6m 51s\tremaining: 3m 5s\n",
      "69:\tlearn: 0.9624816\ttotal: 6m 58s\tremaining: 2m 59s\n",
      "70:\tlearn: 0.9626664\ttotal: 7m 4s\tremaining: 2m 53s\n",
      "71:\tlearn: 0.9627198\ttotal: 7m 10s\tremaining: 2m 47s\n",
      "72:\tlearn: 0.9629489\ttotal: 7m 16s\tremaining: 2m 41s\n",
      "73:\tlearn: 0.9633043\ttotal: 7m 22s\tremaining: 2m 35s\n",
      "74:\tlearn: 0.9634930\ttotal: 7m 28s\tremaining: 2m 29s\n",
      "75:\tlearn: 0.9638418\ttotal: 7m 34s\tremaining: 2m 23s\n",
      "76:\tlearn: 0.9639043\ttotal: 7m 40s\tremaining: 2m 17s\n",
      "77:\tlearn: 0.9643349\ttotal: 7m 46s\tremaining: 2m 11s\n",
      "78:\tlearn: 0.9644994\ttotal: 7m 52s\tremaining: 2m 5s\n",
      "79:\tlearn: 0.9647932\ttotal: 7m 58s\tremaining: 1m 59s\n",
      "80:\tlearn: 0.9649751\ttotal: 8m 4s\tremaining: 1m 53s\n",
      "81:\tlearn: 0.9651247\ttotal: 8m 10s\tremaining: 1m 47s\n",
      "82:\tlearn: 0.9654667\ttotal: 8m 16s\tremaining: 1m 41s\n",
      "83:\tlearn: 0.9655604\ttotal: 8m 22s\tremaining: 1m 35s\n",
      "84:\tlearn: 0.9657201\ttotal: 8m 28s\tremaining: 1m 29s\n",
      "85:\tlearn: 0.9659389\ttotal: 8m 34s\tremaining: 1m 23s\n",
      "86:\tlearn: 0.9661461\ttotal: 8m 40s\tremaining: 1m 17s\n",
      "87:\tlearn: 0.9663036\ttotal: 8m 46s\tremaining: 1m 11s\n",
      "88:\tlearn: 0.9664930\ttotal: 8m 53s\tremaining: 1m 5s\n",
      "89:\tlearn: 0.9667150\ttotal: 8m 59s\tremaining: 59.9s\n",
      "90:\tlearn: 0.9669295\ttotal: 9m 5s\tremaining: 53.9s\n",
      "91:\tlearn: 0.9671202\ttotal: 9m 11s\tremaining: 47.9s\n",
      "92:\tlearn: 0.9672470\ttotal: 9m 17s\tremaining: 42s\n",
      "93:\tlearn: 0.9674898\ttotal: 9m 23s\tremaining: 36s\n",
      "94:\tlearn: 0.9675838\ttotal: 9m 29s\tremaining: 30s\n",
      "95:\tlearn: 0.9677891\ttotal: 9m 35s\tremaining: 24s\n",
      "96:\tlearn: 0.9680457\ttotal: 9m 41s\tremaining: 18s\n",
      "97:\tlearn: 0.9682560\ttotal: 9m 47s\tremaining: 12s\n",
      "98:\tlearn: 0.9684199\ttotal: 9m 53s\tremaining: 6s\n",
      "99:\tlearn: 0.9685963\ttotal: 9m 59s\tremaining: 0us\n",
      "The best F1-score of CatBoostClassifier : 0.743\n",
      "0:\tlearn: 0.9060093\ttotal: 2.82s\tremaining: 4m 38s\n",
      "1:\tlearn: 0.9365670\ttotal: 8.5s\tremaining: 6m 56s\n",
      "2:\tlearn: 0.9429951\ttotal: 13.9s\tremaining: 7m 28s\n",
      "3:\tlearn: 0.9461877\ttotal: 19.7s\tremaining: 7m 53s\n",
      "4:\tlearn: 0.9486988\ttotal: 25.3s\tremaining: 8m\n",
      "5:\tlearn: 0.9499304\ttotal: 31.4s\tremaining: 8m 11s\n",
      "6:\tlearn: 0.9510358\ttotal: 37.3s\tremaining: 8m 15s\n",
      "7:\tlearn: 0.9518343\ttotal: 43.3s\tremaining: 8m 17s\n",
      "8:\tlearn: 0.9526022\ttotal: 49.2s\tremaining: 8m 17s\n",
      "9:\tlearn: 0.9531764\ttotal: 55.3s\tremaining: 8m 18s\n",
      "10:\tlearn: 0.9539571\ttotal: 1m 1s\tremaining: 8m 17s\n",
      "11:\tlearn: 0.9544402\ttotal: 1m 7s\tremaining: 8m 15s\n",
      "12:\tlearn: 0.9550403\ttotal: 1m 13s\tremaining: 8m 12s\n",
      "13:\tlearn: 0.9555056\ttotal: 1m 19s\tremaining: 8m 8s\n",
      "14:\tlearn: 0.9562447\ttotal: 1m 25s\tremaining: 8m 5s\n",
      "15:\tlearn: 0.9565560\ttotal: 1m 31s\tremaining: 8m 1s\n",
      "16:\tlearn: 0.9568980\ttotal: 1m 37s\tremaining: 7m 58s\n",
      "17:\tlearn: 0.9574475\ttotal: 1m 43s\tremaining: 7m 53s\n",
      "18:\tlearn: 0.9575745\ttotal: 1m 50s\tremaining: 7m 49s\n",
      "19:\tlearn: 0.9577659\ttotal: 1m 56s\tremaining: 7m 45s\n",
      "20:\tlearn: 0.9578352\ttotal: 2m 2s\tremaining: 7m 40s\n",
      "21:\tlearn: 0.9578608\ttotal: 2m 8s\tremaining: 7m 36s\n",
      "22:\tlearn: 0.9580945\ttotal: 2m 14s\tremaining: 7m 30s\n",
      "23:\tlearn: 0.9581382\ttotal: 2m 20s\tremaining: 7m 25s\n",
      "24:\tlearn: 0.9581564\ttotal: 2m 26s\tremaining: 7m 20s\n",
      "25:\tlearn: 0.9587472\ttotal: 2m 32s\tremaining: 7m 15s\n",
      "26:\tlearn: 0.9587835\ttotal: 2m 39s\tremaining: 7m 10s\n",
      "27:\tlearn: 0.9587217\ttotal: 2m 45s\tremaining: 7m 5s\n",
      "28:\tlearn: 0.9587631\ttotal: 2m 51s\tremaining: 7m\n",
      "29:\tlearn: 0.9588486\ttotal: 2m 57s\tremaining: 6m 54s\n",
      "30:\tlearn: 0.9588899\ttotal: 3m 3s\tremaining: 6m 49s\n",
      "31:\tlearn: 0.9589129\ttotal: 3m 10s\tremaining: 6m 44s\n",
      "32:\tlearn: 0.9589219\ttotal: 3m 16s\tremaining: 6m 38s\n",
      "33:\tlearn: 0.9589038\ttotal: 3m 22s\tremaining: 6m 33s\n",
      "34:\tlearn: 0.9588784\ttotal: 3m 28s\tremaining: 6m 27s\n",
      "35:\tlearn: 0.9589916\ttotal: 3m 34s\tremaining: 6m 22s\n",
      "36:\tlearn: 0.9590318\ttotal: 3m 41s\tremaining: 6m 16s\n",
      "37:\tlearn: 0.9590375\ttotal: 3m 47s\tremaining: 6m 10s\n",
      "38:\tlearn: 0.9590489\ttotal: 3m 53s\tremaining: 6m 5s\n",
      "39:\tlearn: 0.9590489\ttotal: 3m 59s\tremaining: 5m 59s\n",
      "40:\tlearn: 0.9590744\ttotal: 4m 5s\tremaining: 5m 53s\n",
      "41:\tlearn: 0.9590586\ttotal: 4m 12s\tremaining: 5m 48s\n",
      "42:\tlearn: 0.9590660\ttotal: 4m 18s\tremaining: 5m 42s\n",
      "43:\tlearn: 0.9590824\ttotal: 4m 24s\tremaining: 5m 36s\n",
      "44:\tlearn: 0.9591045\ttotal: 4m 30s\tremaining: 5m 30s\n",
      "45:\tlearn: 0.9590955\ttotal: 4m 36s\tremaining: 5m 25s\n",
      "46:\tlearn: 0.9590921\ttotal: 4m 43s\tremaining: 5m 19s\n",
      "47:\tlearn: 0.9590921\ttotal: 4m 49s\tremaining: 5m 13s\n",
      "48:\tlearn: 0.9590683\ttotal: 4m 55s\tremaining: 5m 7s\n",
      "49:\tlearn: 0.9590938\ttotal: 5m 1s\tremaining: 5m 1s\n",
      "50:\tlearn: 0.9594409\ttotal: 5m 7s\tremaining: 4m 55s\n",
      "51:\tlearn: 0.9594285\ttotal: 5m 13s\tremaining: 4m 49s\n",
      "52:\tlearn: 0.9594245\ttotal: 5m 19s\tremaining: 4m 43s\n",
      "53:\tlearn: 0.9593809\ttotal: 5m 26s\tremaining: 4m 37s\n",
      "54:\tlearn: 0.9593842\ttotal: 5m 32s\tremaining: 4m 31s\n",
      "55:\tlearn: 0.9595073\ttotal: 5m 38s\tremaining: 4m 25s\n",
      "56:\tlearn: 0.9596936\ttotal: 5m 44s\tremaining: 4m 20s\n",
      "57:\tlearn: 0.9598693\ttotal: 5m 50s\tremaining: 4m 14s\n",
      "58:\tlearn: 0.9600753\ttotal: 5m 57s\tremaining: 4m 8s\n",
      "59:\tlearn: 0.9602106\ttotal: 6m 3s\tremaining: 4m 2s\n",
      "60:\tlearn: 0.9604287\ttotal: 6m 9s\tremaining: 3m 56s\n",
      "61:\tlearn: 0.9606394\ttotal: 6m 15s\tremaining: 3m 50s\n",
      "62:\tlearn: 0.9608564\ttotal: 6m 21s\tremaining: 3m 44s\n",
      "63:\tlearn: 0.9610051\ttotal: 6m 28s\tremaining: 3m 38s\n",
      "64:\tlearn: 0.9612250\ttotal: 6m 34s\tremaining: 3m 32s\n",
      "65:\tlearn: 0.9615729\ttotal: 6m 40s\tremaining: 3m 26s\n",
      "66:\tlearn: 0.9619360\ttotal: 6m 46s\tremaining: 3m 20s\n",
      "67:\tlearn: 0.9621684\ttotal: 6m 52s\tremaining: 3m 14s\n",
      "68:\tlearn: 0.9623520\ttotal: 6m 58s\tremaining: 3m 7s\n",
      "69:\tlearn: 0.9624816\ttotal: 7m 4s\tremaining: 3m 1s\n",
      "70:\tlearn: 0.9626664\ttotal: 7m 10s\tremaining: 2m 55s\n",
      "71:\tlearn: 0.9627198\ttotal: 7m 16s\tremaining: 2m 49s\n",
      "72:\tlearn: 0.9629489\ttotal: 7m 22s\tremaining: 2m 43s\n",
      "73:\tlearn: 0.9633043\ttotal: 7m 29s\tremaining: 2m 37s\n",
      "74:\tlearn: 0.9634930\ttotal: 7m 35s\tremaining: 2m 31s\n",
      "75:\tlearn: 0.9638418\ttotal: 7m 41s\tremaining: 2m 25s\n",
      "76:\tlearn: 0.9639043\ttotal: 7m 47s\tremaining: 2m 19s\n",
      "77:\tlearn: 0.9643349\ttotal: 7m 53s\tremaining: 2m 13s\n",
      "78:\tlearn: 0.9644994\ttotal: 7m 59s\tremaining: 2m 7s\n",
      "79:\tlearn: 0.9647932\ttotal: 8m 5s\tremaining: 2m 1s\n",
      "80:\tlearn: 0.9649751\ttotal: 8m 12s\tremaining: 1m 55s\n",
      "81:\tlearn: 0.9651247\ttotal: 8m 18s\tremaining: 1m 49s\n",
      "82:\tlearn: 0.9654667\ttotal: 8m 24s\tremaining: 1m 43s\n",
      "83:\tlearn: 0.9655604\ttotal: 8m 30s\tremaining: 1m 37s\n",
      "84:\tlearn: 0.9657201\ttotal: 8m 36s\tremaining: 1m 31s\n",
      "85:\tlearn: 0.9659389\ttotal: 8m 42s\tremaining: 1m 25s\n",
      "86:\tlearn: 0.9661461\ttotal: 8m 48s\tremaining: 1m 19s\n",
      "87:\tlearn: 0.9663036\ttotal: 8m 54s\tremaining: 1m 12s\n",
      "88:\tlearn: 0.9664930\ttotal: 9m 1s\tremaining: 1m 6s\n",
      "89:\tlearn: 0.9667150\ttotal: 9m 7s\tremaining: 1m\n",
      "90:\tlearn: 0.9669295\ttotal: 9m 13s\tremaining: 54.7s\n",
      "91:\tlearn: 0.9671202\ttotal: 9m 19s\tremaining: 48.7s\n",
      "92:\tlearn: 0.9672470\ttotal: 9m 25s\tremaining: 42.6s\n",
      "93:\tlearn: 0.9674898\ttotal: 9m 32s\tremaining: 36.5s\n",
      "94:\tlearn: 0.9675838\ttotal: 9m 38s\tremaining: 30.4s\n",
      "95:\tlearn: 0.9677891\ttotal: 9m 44s\tremaining: 24.4s\n",
      "96:\tlearn: 0.9680457\ttotal: 9m 50s\tremaining: 18.3s\n",
      "97:\tlearn: 0.9682560\ttotal: 9m 56s\tremaining: 12.2s\n",
      "98:\tlearn: 0.9684199\ttotal: 10m 2s\tremaining: 6.09s\n",
      "99:\tlearn: 0.9685963\ttotal: 10m 8s\tremaining: 0us\n",
      "The final F1-score for test with Pipeline: 0.747\n"
     ]
    }
   ],
   "source": [
    "test.take_res(CatBoostClassifier(), count_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The best F1-score of LGBMClassifier : 0.773\n",
      "The final F1-score for test with Pipeline: 0.780\n"
     ]
    }
   ],
   "source": [
    "test.take_res(LGBMClassifier(), count_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Логистическая регрессия**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "The best F1-score of LogisticRegression : 0.756\n",
      "The final F1-score for test with Pipeline: 0.756\n"
     ]
    }
   ],
   "source": [
    "test.take_res(LogisticRegression(), tf_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Случайный лес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "The best F1-score of RandomForestClassifier : 0.624\n",
      "The final F1-score for test with Pipeline: 0.645\n"
     ]
    }
   ],
   "source": [
    "test.take_res(RandomForestClassifier(), tf_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CatBoostClassfier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "0:\tlearn: 0.9084268\ttotal: 5.16s\tremaining: 8m 30s\n",
      "1:\tlearn: 0.9366817\ttotal: 13.2s\tremaining: 10m 48s\n",
      "2:\tlearn: 0.9419520\ttotal: 21.1s\tremaining: 11m 22s\n",
      "3:\tlearn: 0.9467196\ttotal: 29.4s\tremaining: 11m 46s\n",
      "4:\tlearn: 0.9485391\ttotal: 37.3s\tremaining: 11m 49s\n",
      "5:\tlearn: 0.9506695\ttotal: 45.6s\tremaining: 11m 53s\n",
      "6:\tlearn: 0.9517366\ttotal: 54s\tremaining: 11m 57s\n",
      "7:\tlearn: 0.9527384\ttotal: 1m 2s\tremaining: 11m 57s\n",
      "8:\tlearn: 0.9539003\ttotal: 1m 10s\tremaining: 11m 55s\n",
      "9:\tlearn: 0.9546736\ttotal: 1m 19s\tremaining: 11m 52s\n",
      "10:\tlearn: 0.9557262\ttotal: 1m 27s\tremaining: 11m 49s\n",
      "11:\tlearn: 0.9565375\ttotal: 1m 36s\tremaining: 11m 44s\n",
      "12:\tlearn: 0.9572021\ttotal: 1m 44s\tremaining: 11m 39s\n",
      "13:\tlearn: 0.9578541\ttotal: 1m 52s\tremaining: 11m 33s\n",
      "14:\tlearn: 0.9585230\ttotal: 2m 1s\tremaining: 11m 27s\n",
      "15:\tlearn: 0.9589719\ttotal: 2m 9s\tremaining: 11m 20s\n",
      "16:\tlearn: 0.9594458\ttotal: 2m 18s\tremaining: 11m 14s\n",
      "17:\tlearn: 0.9598498\ttotal: 2m 26s\tremaining: 11m 7s\n",
      "18:\tlearn: 0.9605717\ttotal: 2m 34s\tremaining: 11m\n",
      "19:\tlearn: 0.9608747\ttotal: 2m 43s\tremaining: 10m 53s\n",
      "20:\tlearn: 0.9612379\ttotal: 2m 51s\tremaining: 10m 45s\n",
      "21:\tlearn: 0.9619202\ttotal: 2m 59s\tremaining: 10m 37s\n",
      "22:\tlearn: 0.9622132\ttotal: 3m 8s\tremaining: 10m 30s\n",
      "23:\tlearn: 0.9626469\ttotal: 3m 16s\tremaining: 10m 22s\n",
      "24:\tlearn: 0.9629905\ttotal: 3m 24s\tremaining: 10m 14s\n",
      "25:\tlearn: 0.9631919\ttotal: 3m 33s\tremaining: 10m 7s\n",
      "26:\tlearn: 0.9635016\ttotal: 3m 41s\tremaining: 9m 59s\n",
      "27:\tlearn: 0.9637838\ttotal: 3m 50s\tremaining: 9m 51s\n",
      "28:\tlearn: 0.9640351\ttotal: 3m 58s\tremaining: 9m 43s\n",
      "29:\tlearn: 0.9644951\ttotal: 4m 6s\tremaining: 9m 36s\n",
      "30:\tlearn: 0.9647200\ttotal: 4m 15s\tremaining: 9m 27s\n",
      "31:\tlearn: 0.9647859\ttotal: 4m 23s\tremaining: 9m 19s\n",
      "32:\tlearn: 0.9648632\ttotal: 4m 31s\tremaining: 9m 11s\n",
      "33:\tlearn: 0.9649506\ttotal: 4m 40s\tremaining: 9m 3s\n",
      "34:\tlearn: 0.9650863\ttotal: 4m 48s\tremaining: 8m 56s\n",
      "35:\tlearn: 0.9651985\ttotal: 4m 57s\tremaining: 8m 48s\n",
      "36:\tlearn: 0.9651958\ttotal: 5m 5s\tremaining: 8m 40s\n",
      "37:\tlearn: 0.9652609\ttotal: 5m 13s\tremaining: 8m 32s\n",
      "38:\tlearn: 0.9653543\ttotal: 5m 22s\tremaining: 8m 24s\n",
      "39:\tlearn: 0.9654174\ttotal: 5m 30s\tremaining: 8m 16s\n",
      "40:\tlearn: 0.9654449\ttotal: 5m 39s\tremaining: 8m 8s\n",
      "41:\tlearn: 0.9655046\ttotal: 5m 47s\tremaining: 8m\n",
      "42:\tlearn: 0.9656214\ttotal: 5m 56s\tremaining: 7m 51s\n",
      "43:\tlearn: 0.9655393\ttotal: 6m 4s\tremaining: 7m 43s\n",
      "44:\tlearn: 0.9656583\ttotal: 6m 13s\tremaining: 7m 35s\n",
      "45:\tlearn: 0.9656696\ttotal: 6m 21s\tremaining: 7m 27s\n",
      "46:\tlearn: 0.9656710\ttotal: 6m 29s\tremaining: 7m 19s\n",
      "47:\tlearn: 0.9656971\ttotal: 6m 38s\tremaining: 7m 11s\n",
      "48:\tlearn: 0.9657250\ttotal: 6m 46s\tremaining: 7m 3s\n",
      "49:\tlearn: 0.9656795\ttotal: 6m 55s\tremaining: 6m 55s\n",
      "50:\tlearn: 0.9656581\ttotal: 7m 3s\tremaining: 6m 46s\n",
      "51:\tlearn: 0.9656433\ttotal: 7m 12s\tremaining: 6m 38s\n",
      "52:\tlearn: 0.9656729\ttotal: 7m 20s\tremaining: 6m 30s\n",
      "53:\tlearn: 0.9657004\ttotal: 7m 29s\tremaining: 6m 22s\n",
      "54:\tlearn: 0.9657057\ttotal: 7m 37s\tremaining: 6m 14s\n",
      "55:\tlearn: 0.9657091\ttotal: 7m 45s\tremaining: 6m 6s\n",
      "56:\tlearn: 0.9657615\ttotal: 7m 54s\tremaining: 5m 57s\n",
      "57:\tlearn: 0.9657502\ttotal: 8m 2s\tremaining: 5m 49s\n",
      "58:\tlearn: 0.9657964\ttotal: 8m 11s\tremaining: 5m 41s\n",
      "59:\tlearn: 0.9658065\ttotal: 8m 19s\tremaining: 5m 33s\n",
      "60:\tlearn: 0.9658514\ttotal: 8m 28s\tremaining: 5m 24s\n",
      "61:\tlearn: 0.9658570\ttotal: 8m 36s\tremaining: 5m 16s\n",
      "62:\tlearn: 0.9660014\ttotal: 8m 45s\tremaining: 5m 8s\n",
      "63:\tlearn: 0.9660272\ttotal: 8m 53s\tremaining: 5m\n",
      "64:\tlearn: 0.9660520\ttotal: 9m 2s\tremaining: 4m 51s\n",
      "65:\tlearn: 0.9662522\ttotal: 9m 10s\tremaining: 4m 43s\n",
      "66:\tlearn: 0.9662683\ttotal: 9m 18s\tremaining: 4m 35s\n",
      "67:\tlearn: 0.9663180\ttotal: 9m 27s\tremaining: 4m 26s\n",
      "68:\tlearn: 0.9663864\ttotal: 9m 35s\tremaining: 4m 18s\n",
      "69:\tlearn: 0.9665132\ttotal: 9m 44s\tremaining: 4m 10s\n",
      "70:\tlearn: 0.9666138\ttotal: 9m 52s\tremaining: 4m 2s\n",
      "71:\tlearn: 0.9665964\ttotal: 10m 1s\tremaining: 3m 53s\n",
      "72:\tlearn: 0.9666051\ttotal: 10m 9s\tremaining: 3m 45s\n",
      "73:\tlearn: 0.9665629\ttotal: 10m 18s\tremaining: 3m 37s\n",
      "74:\tlearn: 0.9665764\ttotal: 10m 26s\tremaining: 3m 28s\n",
      "75:\tlearn: 0.9666768\ttotal: 10m 34s\tremaining: 3m 20s\n",
      "76:\tlearn: 0.9667314\ttotal: 10m 43s\tremaining: 3m 12s\n",
      "77:\tlearn: 0.9668519\ttotal: 10m 51s\tremaining: 3m 3s\n",
      "78:\tlearn: 0.9670458\ttotal: 11m\tremaining: 2m 55s\n",
      "79:\tlearn: 0.9672778\ttotal: 11m 8s\tremaining: 2m 47s\n",
      "80:\tlearn: 0.9674601\ttotal: 11m 17s\tremaining: 2m 38s\n",
      "81:\tlearn: 0.9676299\ttotal: 11m 25s\tremaining: 2m 30s\n",
      "82:\tlearn: 0.9678133\ttotal: 11m 34s\tremaining: 2m 22s\n",
      "83:\tlearn: 0.9679706\ttotal: 11m 42s\tremaining: 2m 13s\n",
      "84:\tlearn: 0.9681341\ttotal: 11m 51s\tremaining: 2m 5s\n",
      "85:\tlearn: 0.9683682\ttotal: 11m 59s\tremaining: 1m 57s\n",
      "86:\tlearn: 0.9685600\ttotal: 12m 8s\tremaining: 1m 48s\n",
      "87:\tlearn: 0.9687219\ttotal: 12m 16s\tremaining: 1m 40s\n",
      "88:\tlearn: 0.9689061\ttotal: 12m 24s\tremaining: 1m 32s\n",
      "89:\tlearn: 0.9691981\ttotal: 12m 33s\tremaining: 1m 23s\n",
      "90:\tlearn: 0.9693677\ttotal: 12m 41s\tremaining: 1m 15s\n",
      "91:\tlearn: 0.9695321\ttotal: 12m 50s\tremaining: 1m 6s\n",
      "92:\tlearn: 0.9698785\ttotal: 12m 58s\tremaining: 58.6s\n",
      "93:\tlearn: 0.9700221\ttotal: 13m 6s\tremaining: 50.2s\n",
      "94:\tlearn: 0.9701938\ttotal: 13m 15s\tremaining: 41.8s\n",
      "95:\tlearn: 0.9704171\ttotal: 13m 23s\tremaining: 33.5s\n",
      "96:\tlearn: 0.9707046\ttotal: 13m 32s\tremaining: 25.1s\n",
      "97:\tlearn: 0.9708805\ttotal: 13m 40s\tremaining: 16.7s\n",
      "98:\tlearn: 0.9711783\ttotal: 13m 48s\tremaining: 8.37s\n",
      "99:\tlearn: 0.9713091\ttotal: 13m 57s\tremaining: 0us\n",
      "The best F1-score of CatBoostClassifier : 0.750\n",
      "0:\tlearn: 0.9084268\ttotal: 5.29s\tremaining: 8m 44s\n",
      "1:\tlearn: 0.9366817\ttotal: 13.5s\tremaining: 11m 3s\n",
      "2:\tlearn: 0.9419520\ttotal: 21.7s\tremaining: 11m 40s\n",
      "3:\tlearn: 0.9467196\ttotal: 30.2s\tremaining: 12m 4s\n",
      "4:\tlearn: 0.9485391\ttotal: 38.3s\tremaining: 12m 8s\n",
      "5:\tlearn: 0.9506695\ttotal: 46.8s\tremaining: 12m 13s\n",
      "6:\tlearn: 0.9517366\ttotal: 55.5s\tremaining: 12m 17s\n",
      "7:\tlearn: 0.9527384\ttotal: 1m 4s\tremaining: 12m 17s\n",
      "8:\tlearn: 0.9539003\ttotal: 1m 12s\tremaining: 12m 15s\n",
      "9:\tlearn: 0.9546736\ttotal: 1m 21s\tremaining: 12m 12s\n",
      "10:\tlearn: 0.9557262\ttotal: 1m 29s\tremaining: 12m 8s\n",
      "11:\tlearn: 0.9565375\ttotal: 1m 38s\tremaining: 12m 3s\n",
      "12:\tlearn: 0.9572021\ttotal: 1m 47s\tremaining: 11m 57s\n",
      "13:\tlearn: 0.9578541\ttotal: 1m 55s\tremaining: 11m 51s\n",
      "14:\tlearn: 0.9585230\ttotal: 2m 4s\tremaining: 11m 44s\n",
      "15:\tlearn: 0.9589719\ttotal: 2m 13s\tremaining: 11m 38s\n",
      "16:\tlearn: 0.9594458\ttotal: 2m 21s\tremaining: 11m 32s\n",
      "17:\tlearn: 0.9598498\ttotal: 2m 30s\tremaining: 11m 24s\n",
      "18:\tlearn: 0.9605717\ttotal: 2m 38s\tremaining: 11m 17s\n",
      "19:\tlearn: 0.9608747\ttotal: 2m 47s\tremaining: 11m 10s\n",
      "20:\tlearn: 0.9612379\ttotal: 2m 56s\tremaining: 11m 2s\n",
      "21:\tlearn: 0.9619202\ttotal: 3m 4s\tremaining: 10m 54s\n",
      "22:\tlearn: 0.9622132\ttotal: 3m 13s\tremaining: 10m 46s\n",
      "23:\tlearn: 0.9626469\ttotal: 3m 21s\tremaining: 10m 38s\n",
      "24:\tlearn: 0.9629905\ttotal: 3m 30s\tremaining: 10m 30s\n",
      "25:\tlearn: 0.9631919\ttotal: 3m 38s\tremaining: 10m 22s\n",
      "26:\tlearn: 0.9635016\ttotal: 3m 47s\tremaining: 10m 14s\n",
      "27:\tlearn: 0.9637838\ttotal: 3m 55s\tremaining: 10m 6s\n",
      "28:\tlearn: 0.9640351\ttotal: 4m 4s\tremaining: 9m 58s\n",
      "29:\tlearn: 0.9644951\ttotal: 4m 12s\tremaining: 9m 50s\n",
      "30:\tlearn: 0.9647200\ttotal: 4m 21s\tremaining: 9m 41s\n",
      "31:\tlearn: 0.9647859\ttotal: 4m 29s\tremaining: 9m 33s\n",
      "32:\tlearn: 0.9648632\ttotal: 4m 38s\tremaining: 9m 25s\n",
      "33:\tlearn: 0.9649506\ttotal: 4m 47s\tremaining: 9m 17s\n",
      "34:\tlearn: 0.9650863\ttotal: 4m 55s\tremaining: 9m 9s\n",
      "35:\tlearn: 0.9651985\ttotal: 5m 4s\tremaining: 9m 1s\n",
      "36:\tlearn: 0.9651958\ttotal: 5m 12s\tremaining: 8m 52s\n",
      "37:\tlearn: 0.9652609\ttotal: 5m 21s\tremaining: 8m 44s\n",
      "38:\tlearn: 0.9653543\ttotal: 5m 30s\tremaining: 8m 36s\n",
      "39:\tlearn: 0.9654174\ttotal: 5m 38s\tremaining: 8m 28s\n",
      "40:\tlearn: 0.9654449\ttotal: 5m 47s\tremaining: 8m 20s\n",
      "41:\tlearn: 0.9655046\ttotal: 5m 56s\tremaining: 8m 11s\n",
      "42:\tlearn: 0.9656214\ttotal: 6m 4s\tremaining: 8m 3s\n",
      "43:\tlearn: 0.9655393\ttotal: 6m 13s\tremaining: 7m 55s\n",
      "44:\tlearn: 0.9656583\ttotal: 6m 21s\tremaining: 7m 46s\n",
      "45:\tlearn: 0.9656696\ttotal: 6m 30s\tremaining: 7m 38s\n",
      "46:\tlearn: 0.9656710\ttotal: 6m 39s\tremaining: 7m 30s\n",
      "47:\tlearn: 0.9656971\ttotal: 6m 47s\tremaining: 7m 21s\n",
      "48:\tlearn: 0.9657250\ttotal: 6m 56s\tremaining: 7m 13s\n",
      "49:\tlearn: 0.9656795\ttotal: 7m 5s\tremaining: 7m 5s\n",
      "50:\tlearn: 0.9656581\ttotal: 7m 13s\tremaining: 6m 56s\n",
      "51:\tlearn: 0.9656433\ttotal: 7m 22s\tremaining: 6m 48s\n",
      "52:\tlearn: 0.9656729\ttotal: 7m 31s\tremaining: 6m 39s\n",
      "53:\tlearn: 0.9657004\ttotal: 7m 39s\tremaining: 6m 31s\n",
      "54:\tlearn: 0.9657057\ttotal: 7m 48s\tremaining: 6m 23s\n",
      "55:\tlearn: 0.9657091\ttotal: 7m 56s\tremaining: 6m 14s\n",
      "56:\tlearn: 0.9657615\ttotal: 8m 5s\tremaining: 6m 6s\n",
      "57:\tlearn: 0.9657502\ttotal: 8m 14s\tremaining: 5m 57s\n",
      "58:\tlearn: 0.9657964\ttotal: 8m 22s\tremaining: 5m 49s\n",
      "59:\tlearn: 0.9658065\ttotal: 8m 31s\tremaining: 5m 40s\n",
      "60:\tlearn: 0.9658514\ttotal: 8m 39s\tremaining: 5m 32s\n",
      "61:\tlearn: 0.9658570\ttotal: 8m 48s\tremaining: 5m 23s\n",
      "62:\tlearn: 0.9660014\ttotal: 8m 57s\tremaining: 5m 15s\n",
      "63:\tlearn: 0.9660272\ttotal: 9m 5s\tremaining: 5m 6s\n",
      "64:\tlearn: 0.9660520\ttotal: 9m 14s\tremaining: 4m 58s\n",
      "65:\tlearn: 0.9662522\ttotal: 9m 22s\tremaining: 4m 50s\n",
      "66:\tlearn: 0.9662683\ttotal: 9m 31s\tremaining: 4m 41s\n",
      "67:\tlearn: 0.9663180\ttotal: 9m 40s\tremaining: 4m 33s\n",
      "68:\tlearn: 0.9663864\ttotal: 9m 48s\tremaining: 4m 24s\n",
      "69:\tlearn: 0.9665132\ttotal: 9m 57s\tremaining: 4m 16s\n",
      "70:\tlearn: 0.9666138\ttotal: 10m 6s\tremaining: 4m 7s\n",
      "71:\tlearn: 0.9665964\ttotal: 10m 14s\tremaining: 3m 59s\n",
      "72:\tlearn: 0.9666051\ttotal: 10m 23s\tremaining: 3m 50s\n",
      "73:\tlearn: 0.9665629\ttotal: 10m 32s\tremaining: 3m 42s\n",
      "74:\tlearn: 0.9665764\ttotal: 10m 40s\tremaining: 3m 33s\n",
      "75:\tlearn: 0.9666768\ttotal: 10m 49s\tremaining: 3m 25s\n",
      "76:\tlearn: 0.9667314\ttotal: 10m 57s\tremaining: 3m 16s\n",
      "77:\tlearn: 0.9668519\ttotal: 11m 6s\tremaining: 3m 8s\n",
      "78:\tlearn: 0.9670458\ttotal: 11m 15s\tremaining: 2m 59s\n",
      "79:\tlearn: 0.9672778\ttotal: 11m 23s\tremaining: 2m 50s\n",
      "80:\tlearn: 0.9674601\ttotal: 11m 32s\tremaining: 2m 42s\n",
      "81:\tlearn: 0.9676299\ttotal: 11m 41s\tremaining: 2m 33s\n",
      "82:\tlearn: 0.9678133\ttotal: 11m 49s\tremaining: 2m 25s\n",
      "83:\tlearn: 0.9679706\ttotal: 11m 58s\tremaining: 2m 16s\n",
      "84:\tlearn: 0.9681341\ttotal: 12m 7s\tremaining: 2m 8s\n",
      "85:\tlearn: 0.9683682\ttotal: 12m 15s\tremaining: 1m 59s\n",
      "86:\tlearn: 0.9685600\ttotal: 12m 24s\tremaining: 1m 51s\n",
      "87:\tlearn: 0.9687219\ttotal: 12m 32s\tremaining: 1m 42s\n",
      "88:\tlearn: 0.9689061\ttotal: 12m 41s\tremaining: 1m 34s\n",
      "89:\tlearn: 0.9691981\ttotal: 12m 50s\tremaining: 1m 25s\n",
      "90:\tlearn: 0.9693677\ttotal: 12m 58s\tremaining: 1m 17s\n",
      "91:\tlearn: 0.9695321\ttotal: 13m 7s\tremaining: 1m 8s\n",
      "92:\tlearn: 0.9698785\ttotal: 13m 15s\tremaining: 59.9s\n",
      "93:\tlearn: 0.9700221\ttotal: 13m 24s\tremaining: 51.4s\n",
      "94:\tlearn: 0.9701938\ttotal: 13m 33s\tremaining: 42.8s\n",
      "95:\tlearn: 0.9704171\ttotal: 13m 41s\tremaining: 34.2s\n",
      "96:\tlearn: 0.9707046\ttotal: 13m 50s\tremaining: 25.7s\n",
      "97:\tlearn: 0.9708805\ttotal: 13m 59s\tremaining: 17.1s\n",
      "98:\tlearn: 0.9711783\ttotal: 14m 7s\tremaining: 8.56s\n",
      "99:\tlearn: 0.9713091\ttotal: 14m 15s\tremaining: 0us\n",
      "The final F1-score for test with Pipeline: 0.765\n"
     ]
    }
   ],
   "source": [
    "test.take_res(CatBoostClassifier(), tf_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBMClassifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "The best F1-score of LGBMClassifier : 0.763\n",
      "The final F1-score for test with Pipeline: 0.777\n"
     ]
    }
   ],
   "source": [
    "test.take_res(LGBMClassifier(), tf_vector);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на полученные результаты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>train results</th>\n",
       "      <th>test results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.748298</td>\n",
       "      <td>0.752237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.633473</td>\n",
       "      <td>0.646032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.742558</td>\n",
       "      <td>0.746676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>CountVectorizer</td>\n",
       "      <td>0.772583</td>\n",
       "      <td>0.779808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.755907</td>\n",
       "      <td>0.755568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.623838</td>\n",
       "      <td>0.645135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.750249</td>\n",
       "      <td>0.765029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LGBMClassifier</th>\n",
       "      <td>TfidfVectorizer</td>\n",
       "      <td>0.763492</td>\n",
       "      <td>0.777424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             vectorizer  train results  test results\n",
       "LogisticRegression      CountVectorizer       0.748298      0.752237\n",
       "RandomForestClassifier  CountVectorizer       0.633473      0.646032\n",
       "CatBoostClassifier      CountVectorizer       0.742558      0.746676\n",
       "LGBMClassifier          CountVectorizer       0.772583      0.779808\n",
       "LogisticRegression      TfidfVectorizer       0.755907      0.755568\n",
       "RandomForestClassifier  TfidfVectorizer       0.623838      0.645135\n",
       "CatBoostClassifier      TfidfVectorizer       0.750249      0.765029\n",
       "LGBMClassifier          TfidfVectorizer       0.763492      0.777424"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.take_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "В результате обучения моделей видим следующее:\n",
    "\n",
    "1. Лучшей моделью в плане метрики `F1` оказалась модель `LGBMClassifier` с использованием ящика слов;\n",
    "2. Худшей моделшью оказалась модель `RandomForestClassifier`с использованием ящика в слов;\n",
    "3. Независимо от векторизатора с условием заказчика не справилась модель `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Общий вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была дана задача:\n",
    "\n",
    "> Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Для выполнения работы заказчиком был предоставлен набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Условие заказчика**: метрика качества `F1` не меньше **0,75**\n",
    "\n",
    "После знакомства с данными установили следующие проблемы:\n",
    "\n",
    "1. В текстах комментариев имеются лишние символы. Необходимо провести фильтрацию лишних значений;\n",
    "2. Необходимо для обучения сформировать набор комментариев в лемматизированном виде;\n",
    "3. Учесть сильный дисбаланс классов при обучении модели.\n",
    "\n",
    "На данный момент, данные не готовы для предобработки. Необходимо провести подготовку данных.\n",
    "\n",
    "В процессе подготовки моделей и их обучения выявленные проблемы были учетны и исправлены.\n",
    "\n",
    "В результате обучения получили следующие выводы:\n",
    "\n",
    "1. Лучшей моделью в плане метрики `F1` оказалась модель `LGBMClassifier` с использованием ящика слов;\n",
    "2. Худшей моделшью оказалась модель `RandomForestClassifier`с использованием ящика в слов;\n",
    "3. Независимо от векторизатора с условием заказчика не справилась модель `RandomForestClassifier`.\n",
    "\n",
    "В зависимости от того, как мы подготавливаем данные (лемматизируем ли мы текст, формируем токены, какие векторизаторы используем), а также какие гиперпараметры мы регулируем, мы можем получить разные результаты. "
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2660,
    "start_time": "2022-06-01T19:17:38.385Z"
   },
   {
    "duration": 645,
    "start_time": "2022-06-01T19:17:41.381Z"
   },
   {
    "duration": 3653,
    "start_time": "2022-06-01T19:17:44.065Z"
   },
   {
    "duration": 63,
    "start_time": "2022-06-01T19:17:58.982Z"
   },
   {
    "duration": 281,
    "start_time": "2022-06-01T19:18:06.390Z"
   },
   {
    "duration": 1946,
    "start_time": "2022-06-01T19:18:08.473Z"
   },
   {
    "duration": 49,
    "start_time": "2022-06-01T19:18:11.728Z"
   },
   {
    "duration": 9,
    "start_time": "2022-06-01T19:18:17.369Z"
   },
   {
    "duration": 28,
    "start_time": "2022-06-01T19:19:06.427Z"
   },
   {
    "duration": 32,
    "start_time": "2022-06-01T19:20:24.328Z"
   },
   {
    "duration": 37,
    "start_time": "2022-06-01T19:20:41.228Z"
   },
   {
    "duration": 279,
    "start_time": "2022-06-01T19:21:58.914Z"
   },
   {
    "duration": 6,
    "start_time": "2022-06-01T19:38:45.816Z"
   }
  ],
  "interpreter": {
   "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
